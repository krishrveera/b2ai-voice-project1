{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import timm\n",
    "\n",
    "data_path = '/Users/rachelwang/Downloads/notes/models/csv/adherence_labeled_with_image.csv'\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>task</th>\n",
       "      <th>adherence</th>\n",
       "      <th>file</th>\n",
       "      <th>spectrogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1f9475bb-f13b-4f68-969b-28f20455b3e7</td>\n",
       "      <td>Loudness</td>\n",
       "      <td>5.0</td>\n",
       "      <td>/Users/rachelwang/Downloads/bids_with_sensitiv...</td>\n",
       "      <td>/Users/rachelwang/Downloads/notes/models/adher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1f9475bb-f13b-4f68-969b-28f20455b3e7</td>\n",
       "      <td>Respiration-and-cough-Breath-2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>/Users/rachelwang/Downloads/bids_with_sensitiv...</td>\n",
       "      <td>/Users/rachelwang/Downloads/notes/models/adher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1f9475bb-f13b-4f68-969b-28f20455b3e7</td>\n",
       "      <td>Respiration-and-cough-FiveBreaths-1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>/Users/rachelwang/Downloads/bids_with_sensitiv...</td>\n",
       "      <td>/Users/rachelwang/Downloads/notes/models/adher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f9475bb-f13b-4f68-969b-28f20455b3e7</td>\n",
       "      <td>Respiration-and-cough-ThreeQuickBreaths-2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>/Users/rachelwang/Downloads/bids_with_sensitiv...</td>\n",
       "      <td>/Users/rachelwang/Downloads/notes/models/adher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1f9475bb-f13b-4f68-969b-28f20455b3e7</td>\n",
       "      <td>Maximum-phonation-time-1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>/Users/rachelwang/Downloads/bids_with_sensitiv...</td>\n",
       "      <td>/Users/rachelwang/Downloads/notes/models/adher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    pid  \\\n",
       "0  1f9475bb-f13b-4f68-969b-28f20455b3e7   \n",
       "1  1f9475bb-f13b-4f68-969b-28f20455b3e7   \n",
       "2  1f9475bb-f13b-4f68-969b-28f20455b3e7   \n",
       "3  1f9475bb-f13b-4f68-969b-28f20455b3e7   \n",
       "4  1f9475bb-f13b-4f68-969b-28f20455b3e7   \n",
       "\n",
       "                                        task  adherence  \\\n",
       "0                                   Loudness        5.0   \n",
       "1             Respiration-and-cough-Breath-2        5.0   \n",
       "2        Respiration-and-cough-FiveBreaths-1        5.0   \n",
       "3  Respiration-and-cough-ThreeQuickBreaths-2        4.0   \n",
       "4                   Maximum-phonation-time-1        5.0   \n",
       "\n",
       "                                                file  \\\n",
       "0  /Users/rachelwang/Downloads/bids_with_sensitiv...   \n",
       "1  /Users/rachelwang/Downloads/bids_with_sensitiv...   \n",
       "2  /Users/rachelwang/Downloads/bids_with_sensitiv...   \n",
       "3  /Users/rachelwang/Downloads/bids_with_sensitiv...   \n",
       "4  /Users/rachelwang/Downloads/bids_with_sensitiv...   \n",
       "\n",
       "                                         spectrogram  \n",
       "0  /Users/rachelwang/Downloads/notes/models/adher...  \n",
       "1  /Users/rachelwang/Downloads/notes/models/adher...  \n",
       "2  /Users/rachelwang/Downloads/notes/models/adher...  \n",
       "3  /Users/rachelwang/Downloads/notes/models/adher...  \n",
       "4  /Users/rachelwang/Downloads/notes/models/adher...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adherence label counts:\n",
      "adherence\n",
      "1.0     20\n",
      "2.0     11\n",
      "3.0     25\n",
      "4.0     90\n",
      "5.0    395\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each adherence label\n",
    "label_counts = data['adherence'].value_counts().sort_index()\n",
    "\n",
    "# Print the counts for each label\n",
    "print(\"Adherence label counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the split dataframes to CSV files\n",
    "train_csv_path = '/Users/rachelwang/Downloads/notes/models/train_data_adherence.csv'\n",
    "val_csv_path = '/Users/rachelwang/Downloads/notes/models/val_data_adherence.csv'\n",
    "test_csv_path = '/Users/rachelwang/Downloads/notes/models/test_data_adherence.csv'\n",
    "\n",
    "# Load the split CSV files\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['spectrogram']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.dataframe.iloc[idx]['adherence'] - 1  # 1-based to 0-based label\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = SpectrogramDataset(train_df, transform=transform)\n",
    "val_dataset = SpectrogramDataset(val_df, transform=transform)\n",
    "test_dataset = SpectrogramDataset(test_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EfficientNet model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/50\n",
      "Batch 0, Loss: 4.330209732055664\n",
      "Batch 10, Loss: 0.6061384677886963\n",
      "Epoch [1/50], Loss: 2.1057, Accuracy: 52.47%\n",
      "Validation Loss: 2.0706, Validation Accuracy: 54.63%\n",
      "Starting epoch 2/50\n",
      "Batch 0, Loss: 1.5679315328598022\n",
      "Batch 10, Loss: 3.8740005493164062\n",
      "Epoch [2/50], Loss: 2.0554, Accuracy: 66.98%\n",
      "Validation Loss: 2.3078, Validation Accuracy: 68.52%\n",
      "Starting epoch 3/50\n",
      "Batch 0, Loss: 1.9588309526443481\n",
      "Batch 10, Loss: 1.4499611854553223\n",
      "Epoch [3/50], Loss: 1.5645, Accuracy: 64.51%\n",
      "Validation Loss: 1.4315, Validation Accuracy: 67.59%\n",
      "Starting epoch 4/50\n",
      "Batch 0, Loss: 0.9025329947471619\n",
      "Batch 10, Loss: 0.3136403262615204\n",
      "Epoch [4/50], Loss: 0.8282, Accuracy: 73.15%\n",
      "Validation Loss: 1.8324, Validation Accuracy: 62.04%\n",
      "Starting epoch 5/50\n",
      "Batch 0, Loss: 0.4891032576560974\n",
      "Batch 10, Loss: 0.9837957620620728\n",
      "Epoch [5/50], Loss: 0.9139, Accuracy: 74.69%\n",
      "Validation Loss: 1.2059, Validation Accuracy: 77.78%\n",
      "Starting epoch 6/50\n",
      "Batch 0, Loss: 0.3931542634963989\n",
      "Batch 10, Loss: 0.1384473741054535\n",
      "Epoch [6/50], Loss: 0.6478, Accuracy: 81.17%\n",
      "Validation Loss: 1.5073, Validation Accuracy: 64.81%\n",
      "Starting epoch 7/50\n",
      "Batch 0, Loss: 0.46312010288238525\n",
      "Batch 10, Loss: 0.0777633935213089\n",
      "Epoch [7/50], Loss: 0.4734, Accuracy: 82.10%\n",
      "Validation Loss: 1.5576, Validation Accuracy: 75.00%\n",
      "Starting epoch 8/50\n",
      "Batch 0, Loss: 0.4269654452800751\n",
      "Batch 10, Loss: 1.391302466392517\n",
      "Epoch [8/50], Loss: 0.5077, Accuracy: 87.35%\n",
      "Validation Loss: 1.2936, Validation Accuracy: 73.15%\n",
      "Starting epoch 9/50\n",
      "Batch 0, Loss: 0.2853009104728699\n",
      "Batch 10, Loss: 1.523505687713623\n",
      "Epoch [9/50], Loss: 0.5274, Accuracy: 83.33%\n",
      "Validation Loss: 1.4652, Validation Accuracy: 67.59%\n",
      "Starting epoch 10/50\n",
      "Batch 0, Loss: 0.2067958414554596\n",
      "Batch 10, Loss: 0.7721365690231323\n",
      "Epoch [10/50], Loss: 0.4590, Accuracy: 83.95%\n",
      "Validation Loss: 1.6280, Validation Accuracy: 61.11%\n",
      "Starting epoch 11/50\n",
      "Batch 0, Loss: 0.5121233463287354\n",
      "Batch 10, Loss: 0.41592973470687866\n",
      "Epoch [11/50], Loss: 0.4989, Accuracy: 81.79%\n",
      "Validation Loss: 1.6370, Validation Accuracy: 62.96%\n",
      "Starting epoch 12/50\n",
      "Batch 0, Loss: 0.38698768615722656\n",
      "Batch 10, Loss: 0.8077053427696228\n",
      "Epoch [12/50], Loss: 0.4853, Accuracy: 86.11%\n",
      "Validation Loss: 1.7961, Validation Accuracy: 62.96%\n",
      "Starting epoch 13/50\n",
      "Batch 0, Loss: 0.41129904985427856\n",
      "Batch 10, Loss: 1.866153359413147\n",
      "Epoch [13/50], Loss: 0.6497, Accuracy: 82.10%\n",
      "Validation Loss: 1.8906, Validation Accuracy: 73.15%\n",
      "Starting epoch 14/50\n",
      "Batch 0, Loss: 0.17865340411663055\n",
      "Batch 10, Loss: 0.36622631549835205\n",
      "Epoch [14/50], Loss: 0.3482, Accuracy: 85.19%\n",
      "Validation Loss: 2.3925, Validation Accuracy: 70.37%\n",
      "Starting epoch 15/50\n",
      "Batch 0, Loss: 0.1674756109714508\n",
      "Batch 10, Loss: 2.1562178134918213\n",
      "Epoch [15/50], Loss: 0.5738, Accuracy: 90.74%\n",
      "Validation Loss: 1.4472, Validation Accuracy: 72.22%\n",
      "Early stopping triggered.\n",
      "Training complete.\n",
      "Best model saved at: efficientnet_best_model_adherence.pth\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "best_model_path = 'efficientnet_best_model_adherence.pth'\n",
    "best_val_loss = float('inf')\n",
    "early_stop_patience = 10\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    print(f\"Starting epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()  # Convert labels to LongTensor\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Batch {batch_idx}, Loss: {loss.item()}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()  # Convert labels to LongTensor\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(f\"Best model saved at: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.8237, Test Accuracy: 68.81%\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()  # Convert labels to LongTensor\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 1 Validation Accuracy: 78.90%\n",
      "Fold 2\n",
      "Fold 2 Validation Accuracy: 77.78%\n",
      "Fold 3\n",
      "Fold 3 Validation Accuracy: 75.93%\n",
      "Fold 4\n",
      "Fold 4 Validation Accuracy: 69.44%\n",
      "Fold 5\n",
      "Fold 5 Validation Accuracy: 80.56%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cross-validation setup\n",
    "full_dataset = SpectrogramDataset(data, transform=transform)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)\n",
    "    model.load_state_dict(torch.load('/Users/rachelwang/Downloads/notes/models/efficientnet_best_model_adherence.pth'))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Evaluation on validation set\n",
    "    model.eval()\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_true.extend(labels.cpu().numpy())\n",
    "            val_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    val_accuracy = 100 * accuracy_score(val_true, val_pred)\n",
    "    fold_results.append(val_accuracy)\n",
    "    print(f\"Fold {fold + 1} Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "Fold 1: 78.90%\n",
      "Fold 2: 77.78%\n",
      "Fold 3: 75.93%\n",
      "Fold 4: 69.44%\n",
      "Fold 5: 80.56%\n",
      "Average cross-validation accuracy: 76.52%\n"
     ]
    }
   ],
   "source": [
    "# Print cross-validation results\n",
    "print(\"Cross-validation results:\")\n",
    "for i, accuracy in enumerate(fold_results):\n",
    "    print(f\"Fold {i + 1}: {accuracy:.2f}%\")\n",
    "\n",
    "print(f\"Average cross-validation accuracy: {np.mean(fold_results):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
