{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_18075/396844381.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_18075/396844381.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.3674, Accuracy: 61.44%\n",
      "Validation Loss: 0.9306, Validation Accuracy: 76.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_18075/396844381.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_18075/396844381.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: 0.9371, Accuracy: 72.95%\n",
      "Validation Loss: 0.8150, Validation Accuracy: 76.50%\n",
      "Epoch [3/100], Loss: 0.8294, Accuracy: 74.62%\n",
      "Validation Loss: 0.7944, Validation Accuracy: 76.50%\n",
      "Epoch [4/100], Loss: 0.7459, Accuracy: 76.13%\n",
      "Validation Loss: 0.7500, Validation Accuracy: 76.50%\n",
      "Epoch [5/100], Loss: 0.6929, Accuracy: 75.13%\n",
      "Validation Loss: 0.7081, Validation Accuracy: 76.50%\n",
      "Epoch [6/100], Loss: 0.7053, Accuracy: 76.79%\n",
      "Validation Loss: 0.6697, Validation Accuracy: 76.50%\n",
      "Epoch [7/100], Loss: 0.6813, Accuracy: 75.63%\n",
      "Validation Loss: 0.7017, Validation Accuracy: 76.50%\n",
      "Epoch [8/100], Loss: 0.6477, Accuracy: 77.13%\n",
      "Validation Loss: 0.7303, Validation Accuracy: 76.50%\n",
      "Epoch [9/100], Loss: 0.6119, Accuracy: 77.63%\n",
      "Validation Loss: 0.6671, Validation Accuracy: 76.50%\n",
      "Epoch [10/100], Loss: 0.6199, Accuracy: 76.96%\n",
      "Validation Loss: 0.6511, Validation Accuracy: 76.50%\n",
      "Epoch [11/100], Loss: 0.5749, Accuracy: 77.63%\n",
      "Validation Loss: 0.7922, Validation Accuracy: 76.50%\n",
      "Epoch [12/100], Loss: 0.5715, Accuracy: 76.79%\n",
      "Validation Loss: 0.6786, Validation Accuracy: 81.00%\n",
      "Epoch [13/100], Loss: 0.5375, Accuracy: 77.30%\n",
      "Validation Loss: 0.6382, Validation Accuracy: 81.50%\n",
      "Epoch [14/100], Loss: 0.5085, Accuracy: 79.47%\n",
      "Validation Loss: 0.6373, Validation Accuracy: 81.00%\n",
      "Epoch [15/100], Loss: 0.4809, Accuracy: 80.63%\n",
      "Validation Loss: 0.7449, Validation Accuracy: 70.00%\n",
      "Epoch [16/100], Loss: 0.4877, Accuracy: 80.80%\n",
      "Validation Loss: 1.0529, Validation Accuracy: 40.00%\n",
      "Epoch [17/100], Loss: 0.4629, Accuracy: 81.64%\n",
      "Validation Loss: 0.6614, Validation Accuracy: 71.50%\n",
      "Epoch [18/100], Loss: 0.4247, Accuracy: 82.80%\n",
      "Validation Loss: 0.6172, Validation Accuracy: 79.50%\n",
      "Epoch [19/100], Loss: 0.4209, Accuracy: 81.80%\n",
      "Validation Loss: 0.7976, Validation Accuracy: 60.00%\n",
      "Epoch [20/100], Loss: 0.3922, Accuracy: 85.31%\n",
      "Validation Loss: 0.7086, Validation Accuracy: 68.00%\n",
      "Epoch [21/100], Loss: 0.3967, Accuracy: 84.47%\n",
      "Validation Loss: 0.7475, Validation Accuracy: 81.50%\n",
      "Epoch [22/100], Loss: 0.3622, Accuracy: 83.97%\n",
      "Validation Loss: 0.7436, Validation Accuracy: 82.00%\n",
      "Epoch [23/100], Loss: 0.3260, Accuracy: 87.31%\n",
      "Validation Loss: 1.0291, Validation Accuracy: 45.50%\n",
      "Epoch [24/100], Loss: 0.3236, Accuracy: 86.64%\n",
      "Validation Loss: 0.8168, Validation Accuracy: 81.50%\n",
      "Epoch [25/100], Loss: 0.2912, Accuracy: 89.65%\n",
      "Validation Loss: 0.7737, Validation Accuracy: 76.50%\n",
      "Epoch [26/100], Loss: 0.3168, Accuracy: 87.48%\n",
      "Validation Loss: 1.5228, Validation Accuracy: 80.00%\n",
      "Epoch [27/100], Loss: 0.3049, Accuracy: 88.81%\n",
      "Validation Loss: 0.9472, Validation Accuracy: 81.00%\n",
      "Epoch [28/100], Loss: 0.3483, Accuracy: 86.31%\n",
      "Validation Loss: 1.0338, Validation Accuracy: 57.00%\n",
      "Epoch [29/100], Loss: 0.3302, Accuracy: 86.48%\n",
      "Validation Loss: 0.6497, Validation Accuracy: 79.50%\n",
      "Epoch [30/100], Loss: 0.2710, Accuracy: 88.98%\n",
      "Validation Loss: 0.6662, Validation Accuracy: 72.50%\n",
      "Epoch [31/100], Loss: 0.2574, Accuracy: 89.15%\n",
      "Validation Loss: 0.8250, Validation Accuracy: 76.50%\n",
      "Epoch [32/100], Loss: 0.2417, Accuracy: 90.32%\n",
      "Validation Loss: 0.8601, Validation Accuracy: 78.00%\n",
      "Epoch [33/100], Loss: 0.2557, Accuracy: 90.32%\n",
      "Validation Loss: 1.0652, Validation Accuracy: 81.00%\n",
      "Epoch [34/100], Loss: 0.2394, Accuracy: 90.98%\n",
      "Validation Loss: 1.4105, Validation Accuracy: 82.00%\n",
      "Epoch [35/100], Loss: 0.2354, Accuracy: 91.82%\n",
      "Validation Loss: 1.0816, Validation Accuracy: 80.50%\n",
      "Epoch [36/100], Loss: 0.1898, Accuracy: 92.32%\n",
      "Validation Loss: 0.9230, Validation Accuracy: 69.00%\n",
      "Epoch [37/100], Loss: 0.2204, Accuracy: 92.15%\n",
      "Validation Loss: 0.8212, Validation Accuracy: 71.00%\n",
      "Epoch [38/100], Loss: 0.2072, Accuracy: 91.99%\n",
      "Validation Loss: 0.9466, Validation Accuracy: 82.50%\n",
      "Epoch [39/100], Loss: 0.2029, Accuracy: 92.49%\n",
      "Validation Loss: 1.1034, Validation Accuracy: 80.00%\n",
      "Epoch [40/100], Loss: 0.1810, Accuracy: 94.16%\n",
      "Validation Loss: 1.3976, Validation Accuracy: 82.00%\n",
      "Epoch [41/100], Loss: 0.1555, Accuracy: 93.82%\n",
      "Validation Loss: 0.9322, Validation Accuracy: 70.50%\n",
      "Epoch [42/100], Loss: 0.2046, Accuracy: 92.32%\n",
      "Validation Loss: 1.5440, Validation Accuracy: 79.50%\n",
      "Epoch [43/100], Loss: 0.1644, Accuracy: 94.82%\n",
      "Validation Loss: 0.8552, Validation Accuracy: 79.00%\n",
      "Epoch [44/100], Loss: 0.1595, Accuracy: 93.32%\n",
      "Validation Loss: 1.1318, Validation Accuracy: 76.50%\n",
      "Epoch [45/100], Loss: 0.1554, Accuracy: 93.16%\n",
      "Validation Loss: 1.0988, Validation Accuracy: 84.00%\n",
      "Epoch [46/100], Loss: 0.1422, Accuracy: 94.49%\n",
      "Validation Loss: 1.1304, Validation Accuracy: 82.00%\n",
      "Epoch [47/100], Loss: 0.1231, Accuracy: 94.82%\n",
      "Validation Loss: 1.1778, Validation Accuracy: 82.00%\n",
      "Epoch [48/100], Loss: 0.1268, Accuracy: 95.83%\n",
      "Validation Loss: 0.9691, Validation Accuracy: 77.50%\n",
      "Epoch [49/100], Loss: 0.0926, Accuracy: 96.99%\n",
      "Validation Loss: 1.0579, Validation Accuracy: 78.50%\n",
      "Epoch [50/100], Loss: 0.1125, Accuracy: 95.99%\n",
      "Validation Loss: 1.6815, Validation Accuracy: 53.00%\n",
      "Epoch [51/100], Loss: 0.1779, Accuracy: 94.32%\n",
      "Validation Loss: 1.8449, Validation Accuracy: 52.50%\n",
      "Epoch [52/100], Loss: 0.1585, Accuracy: 93.49%\n",
      "Validation Loss: 1.2658, Validation Accuracy: 82.00%\n",
      "Epoch [53/100], Loss: 0.2156, Accuracy: 92.32%\n",
      "Validation Loss: 0.9030, Validation Accuracy: 79.00%\n",
      "Epoch [54/100], Loss: 0.1511, Accuracy: 93.82%\n",
      "Validation Loss: 1.0832, Validation Accuracy: 66.50%\n",
      "Epoch [55/100], Loss: 0.1285, Accuracy: 95.33%\n",
      "Validation Loss: 1.0753, Validation Accuracy: 83.00%\n",
      "Epoch [56/100], Loss: 0.1021, Accuracy: 95.49%\n",
      "Validation Loss: 1.1772, Validation Accuracy: 82.00%\n",
      "Epoch [57/100], Loss: 0.1048, Accuracy: 96.49%\n",
      "Validation Loss: 1.3974, Validation Accuracy: 63.50%\n",
      "Epoch [58/100], Loss: 0.1104, Accuracy: 95.33%\n",
      "Validation Loss: 0.9393, Validation Accuracy: 82.00%\n",
      "Epoch [59/100], Loss: 0.1270, Accuracy: 95.33%\n",
      "Validation Loss: 1.3536, Validation Accuracy: 83.00%\n",
      "Epoch [60/100], Loss: 0.1358, Accuracy: 95.66%\n",
      "Validation Loss: 1.1076, Validation Accuracy: 81.00%\n",
      "Epoch [61/100], Loss: 0.1622, Accuracy: 93.66%\n",
      "Validation Loss: 0.8090, Validation Accuracy: 75.50%\n",
      "Epoch [62/100], Loss: 0.1421, Accuracy: 95.66%\n",
      "Validation Loss: 1.0560, Validation Accuracy: 80.00%\n",
      "Epoch [63/100], Loss: 0.0819, Accuracy: 97.16%\n",
      "Validation Loss: 1.0490, Validation Accuracy: 82.50%\n",
      "Epoch [64/100], Loss: 0.0655, Accuracy: 98.16%\n",
      "Validation Loss: 1.0182, Validation Accuracy: 82.00%\n",
      "Epoch [65/100], Loss: 0.0879, Accuracy: 96.66%\n",
      "Validation Loss: 1.4288, Validation Accuracy: 83.00%\n",
      "Epoch [66/100], Loss: 0.0943, Accuracy: 97.33%\n",
      "Validation Loss: 1.7348, Validation Accuracy: 58.00%\n",
      "Epoch [67/100], Loss: 0.0684, Accuracy: 97.66%\n",
      "Validation Loss: 1.6986, Validation Accuracy: 82.00%\n",
      "Epoch [68/100], Loss: 0.0710, Accuracy: 97.66%\n",
      "Validation Loss: 1.8183, Validation Accuracy: 80.00%\n",
      "Early stopping triggered.\n",
      "Training complete.\n",
      "Best model saved at: best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import librosa as lb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the annotated data\n",
    "annotated_data = pd.read_csv('/Users/rachelwang/Downloads/modified_data_corrected.csv')\n",
    "\n",
    "# Split the data\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(\n",
    "    annotated_data, annotated_data.quality, stratify=annotated_data.quality, random_state=42, test_size=0.25)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "ytrain = le.fit_transform(ytrain)\n",
    "yval = le.transform(yval)\n",
    "\n",
    "# Feature extraction function\n",
    "def pad_or_truncate(feature, max_len):\n",
    "    if feature.shape[1] < max_len:\n",
    "        pad_width = max_len - feature.shape[1]\n",
    "        feature = np.pad(feature, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        feature = feature[:, :max_len]\n",
    "    return feature\n",
    "\n",
    "def getFeatures(path, max_len=259):\n",
    "    soundArr, sample_rate = lb.load(path)\n",
    "    mfcc = lb.feature.mfcc(y=soundArr, sr=sample_rate)\n",
    "    mfcc = pad_or_truncate(mfcc, max_len)\n",
    "    return mfcc\n",
    "\n",
    "# Custom dataset class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            path = row['file']\n",
    "            mfcc = getFeatures(path)\n",
    "            self.features.append(mfcc)\n",
    "            self.labels.append(row['quality'])\n",
    "\n",
    "        self.labels = le.transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = AudioDataset(Xtrain)\n",
    "val_dataset = AudioDataset(Xval)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class MFCCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MFCCNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 3), padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 2), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 96, kernel_size=(2, 2), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(96)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(96, 128, kernel_size=(2, 2), padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.gmp = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 50)\n",
    "        self.fc2 = nn.Linear(50, 25)\n",
    "        self.fc3 = nn.Linear(25, 8)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(nn.ReLU()(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(nn.ReLU()(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(nn.ReLU()(self.bn3(self.conv3(x))))\n",
    "        x = self.gmp(nn.ReLU()(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(nn.ReLU()(self.fc1(x)))\n",
    "        x = self.dropout(nn.ReLU()(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MFCCNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Early stopping parameters\n",
    "early_stop_patience = 50\n",
    "early_stop_counter = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# File path for saving the best model\n",
    "best_model_path = 'best_model.pth'\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mfcc)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "\n",
    "            outputs = model(mfcc)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(f\"Best model saved at: {best_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
