{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import librosa as lb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the annotated data\n",
    "annotated_data = pd.read_csv('/Users/rachelwang/Downloads/notes/models/csv/quality_labeled.csv')\n",
    "\n",
    "# Split the data into train, validation, and test sets. 60%, 20%, 20%\n",
    "Xtemp, Xtest, ytemp, ytest = train_test_split(\n",
    "    annotated_data, annotated_data.quality, stratify=annotated_data.quality, random_state=42, test_size=0.20)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(\n",
    "    Xtemp, ytemp, stratify=ytemp, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 479\n",
      "Validation set size: 160\n",
      "Test set size: 160\n",
      "\n",
      "Training set label distribution:\n",
      "4    367\n",
      "3     75\n",
      "2     16\n",
      "1     11\n",
      "0     10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set label distribution:\n",
      "4    122\n",
      "3     25\n",
      "2      6\n",
      "0      4\n",
      "1      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set label distribution:\n",
      "4    123\n",
      "3     25\n",
      "2      5\n",
      "1      4\n",
      "0      3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show the numbers for each set\n",
    "print(f\"Training set size: {len(Xtrain)}\")\n",
    "print(f\"Validation set size: {len(Xval)}\")\n",
    "print(f\"Test set size: {len(Xtest)}\")\n",
    "\n",
    "# To also show the distribution of quality labels in each set, convert arrays to Series\n",
    "print(\"\\nTraining set label distribution:\")\n",
    "print(pd.Series(ytrain).value_counts())\n",
    "\n",
    "print(\"\\nValidation set label distribution:\")\n",
    "print(pd.Series(yval).value_counts())\n",
    "\n",
    "print(\"\\nTest set label distribution:\")\n",
    "print(pd.Series(ytest).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "ytrain = le.fit_transform(ytrain)\n",
    "yval = le.transform(yval)\n",
    "ytest = le.transform(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function\n",
    "def pad_or_truncate(feature, max_len):\n",
    "    if feature.shape[1] < max_len:\n",
    "        pad_width = max_len - feature.shape[1]\n",
    "        feature = np.pad(feature, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        feature = feature[:, :max_len]\n",
    "    return feature\n",
    "\n",
    "def getFeatures(path, max_len=2368):\n",
    "    soundArr, sample_rate = lb.load(path)\n",
    "    mfcc = lb.feature.mfcc(y=soundArr, sr=sample_rate)\n",
    "    mfcc = pad_or_truncate(mfcc, max_len)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            path = row['file']\n",
    "            mfcc = getFeatures(path)\n",
    "            self.features.append(mfcc)\n",
    "            self.labels.append(row['quality'])\n",
    "\n",
    "        self.labels = le.transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = AudioDataset(Xtrain)\n",
    "val_dataset = AudioDataset(Xval)\n",
    "test_dataset = AudioDataset(Xtest)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 288]             832\n",
      "       BatchNorm2d-2         [-1, 32, 128, 288]              64\n",
      "         MaxPool2d-3          [-1, 32, 64, 144]               0\n",
      "            Conv2d-4           [-1, 64, 64, 72]          18,496\n",
      "       BatchNorm2d-5           [-1, 64, 64, 72]             128\n",
      "         MaxPool2d-6           [-1, 64, 32, 36]               0\n",
      "            Conv2d-7           [-1, 96, 33, 37]          24,672\n",
      "       BatchNorm2d-8           [-1, 96, 33, 37]             192\n",
      "         MaxPool2d-9           [-1, 96, 16, 18]               0\n",
      "           Conv2d-10          [-1, 128, 17, 19]          49,280\n",
      "      BatchNorm2d-11          [-1, 128, 17, 19]             256\n",
      "AdaptiveMaxPool2d-12            [-1, 128, 1, 1]               0\n",
      "           Linear-13                   [-1, 50]           6,450\n",
      "          Dropout-14                   [-1, 50]               0\n",
      "           Linear-15                   [-1, 25]           1,275\n",
      "          Dropout-16                   [-1, 25]               0\n",
      "           Linear-17                    [-1, 5]             130\n",
      "================================================================\n",
      "Total params: 101,775\n",
      "Trainable params: 101,775\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.42\n",
      "Forward/backward pass size (MB): 27.95\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 28.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "# Define the model\n",
    "class MFCCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MFCCNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 3), padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 2), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 96, kernel_size=(2, 2), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(96)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(96, 128, kernel_size=(2, 2), padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.gmp = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 50)\n",
    "        self.fc2 = nn.Linear(50, 25)\n",
    "        self.fc3 = nn.Linear(25, 5)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(nn.ReLU()(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(nn.ReLU()(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(nn.ReLU()(self.bn3(self.conv3(x))))\n",
    "        x = self.gmp(nn.ReLU()(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(nn.ReLU()(self.fc1(x)))\n",
    "        x = self.dropout(nn.ReLU()(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MFCCNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "summary(model, input_size=(1, 128, 862))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "early_stop_patience = 10\n",
    "early_stop_counter = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# File path for saving the best model\n",
    "best_model_path = 'best_model_updated.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_58021/2446369213.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_58021/2446369213.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5373, Accuracy: 79.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_58021/2446369213.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_58021/2446369213.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8800, Validation Accuracy: 76.25%\n",
      "Epoch [2/100], Loss: 0.5439, Accuracy: 78.08%\n",
      "Validation Loss: 0.6172, Validation Accuracy: 83.12%\n",
      "Epoch [3/100], Loss: 0.5113, Accuracy: 78.71%\n",
      "Validation Loss: 0.9106, Validation Accuracy: 76.88%\n",
      "Epoch [4/100], Loss: 0.5271, Accuracy: 79.12%\n",
      "Validation Loss: 0.7136, Validation Accuracy: 75.62%\n",
      "Epoch [5/100], Loss: 0.5141, Accuracy: 78.91%\n",
      "Validation Loss: 0.6004, Validation Accuracy: 78.75%\n",
      "Epoch [6/100], Loss: 0.5197, Accuracy: 79.12%\n",
      "Validation Loss: 0.7842, Validation Accuracy: 77.50%\n",
      "Epoch [7/100], Loss: 0.4442, Accuracy: 80.79%\n",
      "Validation Loss: 0.6276, Validation Accuracy: 78.75%\n",
      "Epoch [8/100], Loss: 0.4673, Accuracy: 78.91%\n",
      "Validation Loss: 1.0288, Validation Accuracy: 76.88%\n",
      "Epoch [9/100], Loss: 0.4933, Accuracy: 80.79%\n",
      "Validation Loss: 0.5857, Validation Accuracy: 83.12%\n",
      "Epoch [10/100], Loss: 0.4263, Accuracy: 83.09%\n",
      "Validation Loss: 0.6098, Validation Accuracy: 81.25%\n",
      "Epoch [11/100], Loss: 0.4256, Accuracy: 82.46%\n",
      "Validation Loss: 0.7390, Validation Accuracy: 69.38%\n",
      "Epoch [12/100], Loss: 0.4378, Accuracy: 83.30%\n",
      "Validation Loss: 0.6166, Validation Accuracy: 84.38%\n",
      "Epoch [13/100], Loss: 0.3996, Accuracy: 82.46%\n",
      "Validation Loss: 0.7308, Validation Accuracy: 80.00%\n",
      "Epoch [14/100], Loss: 0.3617, Accuracy: 85.39%\n",
      "Validation Loss: 1.2255, Validation Accuracy: 43.75%\n",
      "Epoch [15/100], Loss: 0.4138, Accuracy: 83.30%\n",
      "Validation Loss: 1.2675, Validation Accuracy: 78.75%\n",
      "Epoch [16/100], Loss: 0.3805, Accuracy: 85.39%\n",
      "Validation Loss: 0.9606, Validation Accuracy: 53.12%\n",
      "Epoch [17/100], Loss: 0.4387, Accuracy: 83.72%\n",
      "Validation Loss: 0.6355, Validation Accuracy: 84.38%\n",
      "Epoch [18/100], Loss: 0.3569, Accuracy: 86.22%\n",
      "Validation Loss: 1.1489, Validation Accuracy: 47.50%\n",
      "Epoch [19/100], Loss: 0.3682, Accuracy: 85.18%\n",
      "Validation Loss: 0.8696, Validation Accuracy: 82.50%\n",
      "Early stopping triggered.\n",
      "Training complete.\n",
      "Best model saved at: best_model_updated.pth\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "        # print(f'labels in the training: {labels}')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mfcc)\n",
    "        # print(f'output in the training: {outputs}')\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "\n",
    "            outputs = model(mfcc)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(f\"Best model saved at: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_58021/335472188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
      "/var/folders/nq/w309ddbn44vc89_05x5yy70c0000gn/T/ipykernel_58021/335472188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5566, Test Accuracy: 80.62%\n"
     ]
    }
   ],
   "source": [
    "# Load the best model for testing\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "# Test evaluation\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        mfcc = torch.tensor(features).unsqueeze(1).float().to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "\n",
    "        outputs = model(mfcc)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
